{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GDianaS/machine-learning-basics/blob/main/03_Multiple_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b3a33de",
      "metadata": {
        "id": "0b3a33de"
      },
      "source": [
        "### Multiple Linear Regression ###\n",
        "$$\n",
        "y = b_{0} + b_{1}*x_{1} + b_{2}*x_{2}+ ... +b_{n}*x_{n}\n",
        "$$\n",
        "1. Linearidade\n",
        "2. Homescedasticity (homocedasticidade)\n",
        "3. Multivariate normality\n",
        "4. Independence of erros\n",
        "5. Lack of multicollinearity\n",
        "\n",
        "### Dummy Variable Trap ###\n",
        "\n",
        "**Categorical Variable** -> cria-se dummy variables através da criação de novas colunas que tem aparência semelhante a uma tabela verdade. Quebra-se assim a variavel categorica em outras variaveis numéricas. Se estiver somente duas opções pode se usar somente uma coluna com 1 e 0. Assim não é preciso inserir todas as dummy variables \"D\" (switches) no dataset\n",
        "\n",
        "$$\n",
        "y = b_{0} + b_{1}*x_{1} + b_{2}*x_{2} + b_{3}*x_{3} + b_{4}*D_{1}+b_{5}*D_{2}\n",
        "$$\n",
        "\n",
        "> Você não pode ter a constante ($ b_{0} $) e as todas as dummy variaveis juntas. So when building a model, always omit one dummy variable.\n",
        "\n",
        "### P-Value ###\n",
        "Quando temos um evento com probabilidade de acontecer menor ou igual a 5% ($\\alpha$=0.05) sentimos uma certa desconfiança ligada ao acontecimento desse evento, a partir do qual é um valor que nós permite rejeitar ou aceitar uma hipótese relacionada a esse evento.\n",
        "\n",
        "### Building a Model ###\n",
        "**\"All-in\"** : usar todas as variáveis. Você sabe que elas são todas necessárias para construir o modelo. \n",
        "\n",
        "**Backward Elimination**:\n",
        " 1. STEP 1: Select a significance level to stay in the model (e.g. SL = 0.05)\n",
        " 2. STEP 2: Fit the full model with all possible predictors\n",
        " 3. STEP 3: Consider the predictor with the __highest__ P-value. If P>SL, go to STEP 4, otherwise go to FIN\n",
        " 4. STEP 4: Remove the predictor\n",
        " 5. STEP 5: Fit model without this variable* Go back to STEP 3\n",
        " \n",
        " FIN: YOU MODEL IS READY\n",
        " \n",
        " **Forward Selection**:\n",
        " 1. STEP 1: Select a significance level to enter in the model (e.g. SL = 0.05)\n",
        " 2. STEP 2: Fit all simple regression models y ~x$_{n}$. Nós pegamos a varrável dependente (y) e criamos um modelo de regressão com cada variável independente. Select the one with __lowest__ P-value.\n",
        " 3. STEP 3: Keep this variable and fit all possible models with one extra predictor added to the one(s) you already have. Selecionamos uma regressão linear simples com uma variável para depois construir todas as regressões lineares possíveis com duas variáveis, ou seja, adicionamos todas as possíveis todas as outras variáveis uma por uma.\n",
        " 4. STEP 4: Consider the predictor with the __lowest__ P-value. If P < SL, got to STEP 3 (Agora para o PASSO 3 vc terá duas variáveis e vai adicionar uma terceira), otherwise go to FIN\n",
        " \n",
        " FIN: DON´T KEEP THE CURENT MODEL. KEEP THE PREVIOUS MODEL\n",
        " \n",
        " **Bidirectional Elimination**:\n",
        " 1. STEP 1: Select a significance level to enter an to stay in the model (e.g. SLENTER = 0.05, SLSTAY = 0.05)\n",
        " 2. STEP 2: New variables must have: P < SLENTER to enter\n",
        " 3. STEP 3: Performa ALL steps of Backward Elimination. Old variables ust have P < SLSTAY to stay. Go back to STEP 2\n",
        " 4. STEP 4: No new variables can enter and no old variables can exit\n",
        " \n",
        " FIN: YOU MODEL IS READY\n",
        " \n",
        " **All Possible Models**:\n",
        "  1. STEP 1: Select a criterion of goodness of fit.\n",
        "  2. STEP 2: Construct all possible regression models: $2^n - 1$ total combinations, n being the numbers of columns\n",
        "  3. STEP 3: Select the one with the best criterion\n",
        "  \n",
        "   FIN: YOU MODEL IS READY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b77814eb",
      "metadata": {
        "id": "b77814eb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ebfffd3",
      "metadata": {
        "id": "0ebfffd3"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('Dataset/50_Startups.csv')\n",
        "X = dataset.iloc[:,:-1].values\n",
        "y = dataset.iloc[:,-1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88563887",
      "metadata": {
        "scrolled": true,
        "id": "88563887",
        "outputId": "76170dab-0f9b-4300-f154-e77e831cac3f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>R&amp;D Spend</th>\n",
              "      <th>Administration</th>\n",
              "      <th>Marketing Spend</th>\n",
              "      <th>State</th>\n",
              "      <th>Profit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>165349.20</td>\n",
              "      <td>136897.80</td>\n",
              "      <td>471784.10</td>\n",
              "      <td>New York</td>\n",
              "      <td>192261.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>162597.70</td>\n",
              "      <td>151377.59</td>\n",
              "      <td>443898.53</td>\n",
              "      <td>California</td>\n",
              "      <td>191792.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>153441.51</td>\n",
              "      <td>101145.55</td>\n",
              "      <td>407934.54</td>\n",
              "      <td>Florida</td>\n",
              "      <td>191050.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>144372.41</td>\n",
              "      <td>118671.85</td>\n",
              "      <td>383199.62</td>\n",
              "      <td>New York</td>\n",
              "      <td>182901.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>142107.34</td>\n",
              "      <td>91391.77</td>\n",
              "      <td>366168.42</td>\n",
              "      <td>Florida</td>\n",
              "      <td>166187.94</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
              "0  165349.20       136897.80        471784.10    New York  192261.83\n",
              "1  162597.70       151377.59        443898.53  California  191792.06\n",
              "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
              "3  144372.41       118671.85        383199.62    New York  182901.99\n",
              "4  142107.34        91391.77        366168.42     Florida  166187.94"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4be67c02",
      "metadata": {
        "id": "4be67c02"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder=\"passthrough\")\n",
        "X = np.array(ct.fit_transform(X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7be41de9",
      "metadata": {
        "scrolled": true,
        "id": "7be41de9",
        "outputId": "c3bab1cc-2e6d-485e-aa47-5cf7e1cfd828"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.0 0.0 1.0 165349.2 136897.8 471784.1]\n",
            " [1.0 0.0 0.0 162597.7 151377.59 443898.53]\n",
            " [0.0 1.0 0.0 153441.51 101145.55 407934.54]\n",
            " [0.0 0.0 1.0 144372.41 118671.85 383199.62]\n",
            " [0.0 1.0 0.0 142107.34 91391.77 366168.42]\n",
            " [0.0 0.0 1.0 131876.9 99814.71 362861.36]\n",
            " [1.0 0.0 0.0 134615.46 147198.87 127716.82]\n",
            " [0.0 1.0 0.0 130298.13 145530.06 323876.68]\n",
            " [0.0 0.0 1.0 120542.52 148718.95 311613.29]\n",
            " [1.0 0.0 0.0 123334.88 108679.17 304981.62]\n",
            " [0.0 1.0 0.0 101913.08 110594.11 229160.95]\n",
            " [1.0 0.0 0.0 100671.96 91790.61 249744.55]\n",
            " [0.0 1.0 0.0 93863.75 127320.38 249839.44]\n",
            " [1.0 0.0 0.0 91992.39 135495.07 252664.93]\n",
            " [0.0 1.0 0.0 119943.24 156547.42 256512.92]\n",
            " [0.0 0.0 1.0 114523.61 122616.84 261776.23]\n",
            " [1.0 0.0 0.0 78013.11 121597.55 264346.06]\n",
            " [0.0 0.0 1.0 94657.16 145077.58 282574.31]\n",
            " [0.0 1.0 0.0 91749.16 114175.79 294919.57]\n",
            " [0.0 0.0 1.0 86419.7 153514.11 0.0]\n",
            " [1.0 0.0 0.0 76253.86 113867.3 298664.47]\n",
            " [0.0 0.0 1.0 78389.47 153773.43 299737.29]\n",
            " [0.0 1.0 0.0 73994.56 122782.75 303319.26]\n",
            " [0.0 1.0 0.0 67532.53 105751.03 304768.73]\n",
            " [0.0 0.0 1.0 77044.01 99281.34 140574.81]\n",
            " [1.0 0.0 0.0 64664.71 139553.16 137962.62]\n",
            " [0.0 1.0 0.0 75328.87 144135.98 134050.07]\n",
            " [0.0 0.0 1.0 72107.6 127864.55 353183.81]\n",
            " [0.0 1.0 0.0 66051.52 182645.56 118148.2]\n",
            " [0.0 0.0 1.0 65605.48 153032.06 107138.38]\n",
            " [0.0 1.0 0.0 61994.48 115641.28 91131.24]\n",
            " [0.0 0.0 1.0 61136.38 152701.92 88218.23]\n",
            " [1.0 0.0 0.0 63408.86 129219.61 46085.25]\n",
            " [0.0 1.0 0.0 55493.95 103057.49 214634.81]\n",
            " [1.0 0.0 0.0 46426.07 157693.92 210797.67]\n",
            " [0.0 0.0 1.0 46014.02 85047.44 205517.64]\n",
            " [0.0 1.0 0.0 28663.76 127056.21 201126.82]\n",
            " [1.0 0.0 0.0 44069.95 51283.14 197029.42]\n",
            " [0.0 0.0 1.0 20229.59 65947.93 185265.1]\n",
            " [1.0 0.0 0.0 38558.51 82982.09 174999.3]\n",
            " [1.0 0.0 0.0 28754.33 118546.05 172795.67]\n",
            " [0.0 1.0 0.0 27892.92 84710.77 164470.71]\n",
            " [1.0 0.0 0.0 23640.93 96189.63 148001.11]\n",
            " [0.0 0.0 1.0 15505.73 127382.3 35534.17]\n",
            " [1.0 0.0 0.0 22177.74 154806.14 28334.72]\n",
            " [0.0 0.0 1.0 1000.23 124153.04 1903.93]\n",
            " [0.0 1.0 0.0 1315.46 115816.21 297114.46]\n",
            " [1.0 0.0 0.0 0.0 135426.92 0.0]\n",
            " [0.0 0.0 1.0 542.05 51743.15 0.0]\n",
            " [1.0 0.0 0.0 0.0 116983.8 45173.06]]\n"
          ]
        }
      ],
      "source": [
        "#the encoder columns go to the front\n",
        "#New York (001) , California(100), Florida(010)\n",
        "print(X)\n",
        "#Não é preciso escalar recursos em Multiple Linear Regression, pois os coeficientes compensarão as escalas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aec0136c",
      "metadata": {
        "id": "aec0136c"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                    y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab8d31d7",
      "metadata": {
        "id": "ab8d31d7",
        "outputId": "256ada53-f8e7-4962-ed8f-1c76d6d4a262"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# A classe automaticamente evita the Dummy Variable Trap e faz the Backward Elimination\n",
        "from sklearn.linear_model import LinearRegression\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94e5b405",
      "metadata": {
        "id": "94e5b405",
        "outputId": "d811e807-fda8-45d1-868c-0e67e435f1c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[103015.2  103282.38]\n",
            " [132582.28 144259.4 ]\n",
            " [132447.74 146121.95]\n",
            " [ 71976.1   77798.83]\n",
            " [178537.48 191050.39]\n",
            " [116161.24 105008.31]\n",
            " [ 67851.69  81229.06]\n",
            " [ 98791.73  97483.56]\n",
            " [113969.44 110352.25]\n",
            " [167921.07 166187.94]]\n"
          ]
        }
      ],
      "source": [
        "y_pred = regressor.predict(X_test)\n",
        "np.set_printoptions(precision=2)  #Duas casas decimais\n",
        "#reshape(linhas, colunas)\n",
        "print(\n",
        "    np.concatenate(\n",
        "        (y_pred.reshape(len(y_pred), 1), y_test.reshape(len(y_test), 1)),\n",
        "        axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5eb3ab9",
      "metadata": {
        "id": "f5eb3ab9"
      },
      "source": [
        "### Making a single prediction (for example the profit of a startup with R&D Spend = 160000, Administration Spend = 130000, Marketing Spend = 300000 and State = 'California') ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83b81bbe",
      "metadata": {
        "id": "83b81bbe",
        "outputId": "8a44f77f-0038-4461-a9bf-8c2d3510e863"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[181566.92]\n"
          ]
        }
      ],
      "source": [
        "#predict methos always expects a 2D array as the input\n",
        "#12→scalar \n",
        "#[12]→1D array \n",
        "#[[12]]→2D array\n",
        "print(regressor.predict([[1,0,0,160000,130000,300000]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27a5fa18",
      "metadata": {
        "id": "27a5fa18",
        "outputId": "6ac1af03-57c4-478c-a9e2-8aac04e11c51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 8.66e+01 -8.73e+02  7.86e+02  7.73e-01  3.29e-02  3.66e-02]\n",
            "42467.52924854249\n"
          ]
        }
      ],
      "source": [
        "print(regressor.coef_)\n",
        "print(regressor.intercept_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8181d25",
      "metadata": {
        "id": "e8181d25"
      },
      "source": [
        "\n",
        "$$\\textrm{Profit} = 86.6 \\times \\textrm{Dummy State 1} - 873 \\times \\textrm{Dummy State 2} + 786 \\times \\textrm{Dummy State 3} + 0.773 \\times \\textrm{R&D Spend} + 0.0329 \\times \\textrm{Administration} + 0.0366 \\times \\textrm{Marketing Spend} + 42467.53$$"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {
        "height": "55px",
        "width": "160px"
      },
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "03 - Multiple Linear Regression.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}